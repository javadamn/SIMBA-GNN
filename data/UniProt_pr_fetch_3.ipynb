{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af9d54-feb2-4908-be3b-99fd4fe3f84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra\n",
    "import requests\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c20c3bf-b777-4e18-b211-017c33468dbe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# fetch_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0157781e-0b19-4d79-9310-80863f38010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_pr(taxon_id, reviewed=False, format='fasta', limit=1000):\n",
    "    base_url = \"https://rest.uniprot.org/uniprotkb/stream\"\n",
    "    query = f\"organism_id:{taxon_id}\"\n",
    "    if reviewed:\n",
    "        query += \" AND reviewed:true\"\n",
    "\n",
    "    params = {\"query\": query, \"format\": format, \"size\": limit}\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        with open(f\"/home/aac/Mohammad/GNN/MetaBiomeX-main/data/fastas/uniprot_{taxon_id}.fasta\", \"w\") as f:\n",
    "            f.write(response.text)\n",
    "        return response.text \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e092243-2192-44d2-83eb-3ccdd1c87a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list= pd.read_csv('/home/aac/Mohammad/GNN/MetaBiomeX-main/data/ListofModelsforSpecies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eb200d-f9af-4bc5-88ba-e6f8197ec49b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xml_files = []\n",
    "\n",
    "for entry in models_list['models'].dropna():\n",
    "    found = re.findall(r'\\b[\\w\\-\\.]+\\.xml\\b', str(entry))\n",
    "    xml_files.extend(found)\n",
    "\n",
    "xml_files = sorted(set(xml_files))\n",
    "xml_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68061f37-3539-4e87-b742-ced539130b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Strain_cleaned'] = df['Strain'].str.replace('.xml', '', regex=False)\n",
    "\n",
    "\n",
    "base_url = \"https://www.vmh.life/_api/microbes/?reconstruction=\"\n",
    "\n",
    "def get_ncbiid(strain):\n",
    "    response = requests.get(base_url + strain)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data.get(\"results\"):\n",
    "            return data[\"results\"][0].get(\"ncbiid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37346a0-4d36-41a6-b007-4530363dba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_df = pd.DataFrame(xml_files, columns=['XML File'])\n",
    "xml_df['strain_name'] = xml_df['XML File'].str.replace('.xml', '', regex=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aeb21f-a65f-40d3-82b3-5bb82cacd1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_df['strain_name'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe90a156-af46-44f4-98ad-8711812091f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= get_ncbiid(xml_df['strain_name'][0])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacbdea5-4441-47b7-a426-100310e92fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173343b3-4d84-418a-bb97-d79afadeaaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_df['ncbiid'] = xml_df['strain_name'].apply(get_ncbiid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4196d33c-b9b1-453e-b83a-1e971f04edbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f570d02-6b46-4460-a9fd-4f21c8bd7417",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/aac/Mohammad/GNN/MetaBiomeX-main/data/strain_with_NCBIids.csv\"\n",
    "xml_df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6304f3a0-4496-4790-a8e6-dd4f551aa202",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Fetch Pr. seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c207afe-bc8e-40d7-b7fa-745a7bfc1e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "xml_df= pd.read_csv(\"/home/aac/Mohammad/GNN/MetaBiomeX-main/data/strain_with_NCBIids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1ea0bb-8923-4b14-bf10-9665cdb84b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi_ids = xml_df['ncbiid']#.dropna().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded99081-1de5-4a3b-bc81-282486a1e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetched_files = {}\n",
    "from tqdm import tqdm\n",
    "for taxon_id in tqdm(ncbi_ids[130:140]):\n",
    "    # print(f\"fetching: {taxon_id}\")\n",
    "    try:\n",
    "        file_path = fetch_pr(taxon_id=int(taxon_id), reviewed=False)\n",
    "        if file_path:\n",
    "            fetched_files[taxon_id] = file_path\n",
    "            # print('done')\n",
    "    except Exception as e:\n",
    "        fetched_files[taxon_id] = f\"Error: {str(e)}\"\n",
    "        print('failed')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7845db09-500b-4b23-8b27-78fd8f6325a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi_ids[130:140]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3eeb5d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Number of Downloaded sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57778289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "\n",
    "empty_fasta = []\n",
    "def process_fasta(file_path):\n",
    "    \"\"\"\n",
    "    Process a single FASTA file:\n",
    "    - Count sequences\n",
    "    - Determine the min and max sequence lengths in the file\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    min_length = float('inf')\n",
    "    max_length = 0\n",
    "    \n",
    "    # Parse each record in the FASTA file\n",
    "    for record in SeqIO.parse(file_path, \"fasta\"):\n",
    "        seq_len = len(record.seq)\n",
    "        total += 1\n",
    "        if seq_len < min_length:\n",
    "            min_length = seq_len\n",
    "        if seq_len > max_length:\n",
    "            max_length = seq_len\n",
    "            \n",
    "    # Handle files that might be empty\n",
    "    if total == 0:\n",
    "        min_length = 0\n",
    "        \n",
    "    return total, min_length, max_length,file_path\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the directory containing the FASTA files\n",
    "    directory = \"/home/aac/Mohammad/GNN/MetaBiomeX-main/data/fastas\"  # change this to your directory path\n",
    "    # Gather all FASTA files (adjust the pattern if your file extension differs)\n",
    "    fasta_files = glob.glob(os.path.join(directory, \"*.fasta\"))\n",
    "    \n",
    "    total_sequences = 0\n",
    "    overall_min = float('inf')\n",
    "    overall_max = 0\n",
    "\n",
    "    # Use a multiprocessing Pool to process the FASTA files concurrently\n",
    "    with mp.Pool() as pool:\n",
    "        # Use tqdm to track progress of the multiprocessing jobs\n",
    "        results = list(tqdm(pool.imap_unordered(process_fasta, fasta_files),\n",
    "                            total=len(fasta_files),\n",
    "                            desc=\"Processing FASTA files\"))\n",
    "    \n",
    "    # Combine the results from each file\n",
    "    for total, min_length, max_length,path in results:\n",
    "        if total ==0:\n",
    "            empty_fasta.append(path)\n",
    "        total_sequences += total\n",
    "        overall_min = min(overall_min, min_length)\n",
    "        overall_max = max(overall_max, max_length)\n",
    "    \n",
    "    # If no sequences were found overall, adjust the minimum length\n",
    "    if overall_min == float('inf'):\n",
    "        overall_min = 0\n",
    "\n",
    "    print(\"Total sequences:\", total_sequences)\n",
    "    print(\"Min sequence length:\", overall_min)\n",
    "    print(\"Max sequence length:\", overall_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1889d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_ids = ([int(w.replace('.fasta','').split('_')[-1]) for w in empty_fasta])\n",
    "len(empty_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e969446",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Redownload empty ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b4b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetched_files = {}\n",
    "from tqdm import tqdm\n",
    "for taxon_id in tqdm(empty_ids):\n",
    "    # print(f\"fetching: {taxon_id}\")\n",
    "    try:\n",
    "        file_path = fetch_pr(taxon_id=int(taxon_id), reviewed=False)\n",
    "        if file_path:\n",
    "            fetched_files[taxon_id] = file_path\n",
    "            # print('done')\n",
    "    except Exception as e:\n",
    "        fetched_files[taxon_id] = f\"Error: {str(e)}\"\n",
    "        print('failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d3b60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40acaff-45d5-466a-bf8d-e75e38bdf692",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Start from here ::::::::::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f40986b-c05a-440c-8f78-c3886e0d4c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_map = pd.read_csv('anaerobic_strains_map.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93faee97-d59b-428f-be18-3d36b500b10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60850af-f6e5-4cfb-9c35-a56f38802d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_map[node_map['ID'] == 812]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dddda2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [int(x) for x in ['812', '383', '44', '334', '422', '444', '477', '534', '399', '302',\n",
    "                  '141', '129', '752', '21', '268', '484', '23', '224', '78', '641',\n",
    "                  '548', '549', '34', '528', '143', '118', '152', '343', '123', '72',\n",
    "                  '239', '688', '150', '467', '164', '562', '13', '276', '203', '104',\n",
    "                  '645', '530', '131', '24', '664', '529', '431', '209', '350', '502',\n",
    "                  '540', '315', '19', '271', '119', '12', '331', '304', '349', '456',\n",
    "                  '751', '200', '67', '792', '395', '656', '55', '174', '788', '192',\n",
    "                  '782', '489', '326', '538', '503']]\n",
    "\n",
    "final_nodes = node_map[node_map['ID'].isin(nodes)]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e110377-6670-4461-9ebb-e5a3cdecb4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_nodes.shape # should be (75 in 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8ca50b-4507-46bd-aecb-30f12bfd90bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098a7f7b-b327-48a4-ab51-93122b72081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_ids=[469617,\n",
    " 273526,\n",
    " 440497,\n",
    " 702444,\n",
    " 1235815,\n",
    " 435837,\n",
    " 888048,\n",
    " 457424,\n",
    " 563194,\n",
    " 575595,\n",
    " 1121102,\n",
    " 1215915,\n",
    " 1400136,\n",
    " 742820,\n",
    " 1328388,\n",
    " 411901,\n",
    " 1262650,\n",
    " 525337,\n",
    " 1328337,\n",
    " 469599,\n",
    " 888727,\n",
    " 702443,\n",
    " 1322347,\n",
    " 411487,\n",
    " 469602,\n",
    " 536233,\n",
    " 649757,\n",
    " 1353979,\n",
    " 663952,\n",
    " 1121342,\n",
    " 469618,\n",
    " 657324,\n",
    " 1035196,\n",
    " 1122982,\n",
    " 525279,\n",
    " 871541,\n",
    " 1440052,\n",
    " 1316931,\n",
    " 469616,\n",
    " 469603,\n",
    " 883166,\n",
    " 657316,\n",
    " 1121445,\n",
    " 944562,\n",
    " 1203540,\n",
    " 562982,\n",
    " 1437595,\n",
    " 1074451,\n",
    " 469615,\n",
    " 1384484]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8efcab-ef9c-402a-8662-f093485d2883",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_ids_inNodes = node_map[node_map['ncbiid'].isin(np.array(empty_ids))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ccaa98-f3ae-4462-b604-cd00cf82cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_ids_inNodes.shape # should be (50 in 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a60c88c-cac0-4262-a8fc-4f957707726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_ids_inNodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c89247-0670-4b61-a12b-432109184821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "import time\n",
    "\n",
    "Entrez.email = \"javadamn@gmail.com\" \n",
    "\n",
    "taxonomy_ids = empty_ids_inNodes['ncbiid'] #['1074451', '649757']\n",
    "\n",
    "for tax_id in taxonomy_ids:\n",
    "    print(f\"\\nSearching NCBI protein database for Taxonomy ID: {tax_id}\")\n",
    "    \n",
    "    try:\n",
    "        handle = Entrez.esearch(db=\"protein\", term=f\"txid{tax_id}[Organism:exp]\", retmax=5000)\n",
    "        record = Entrez.read(handle)\n",
    "        handle.close()\n",
    "\n",
    "        ids = record[\"IdList\"]\n",
    "\n",
    "        if not ids:\n",
    "            print(f\"No protein records {tax_id}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"found {len(ids)} pr records\")\n",
    "\n",
    "        batch_size = 500 \n",
    "        filename = f\"ncbi_taxonomy_{tax_id}.fasta\"\n",
    "        with open(filename, \"w\") as out_f:\n",
    "            for start in range(0, len(ids), batch_size):\n",
    "                end = min(start + batch_size, len(ids))\n",
    "                id_batch = ids[start:end]\n",
    "                fetch_handle = Entrez.efetch(db=\"protein\", id=id_batch, rettype=\"fasta\", retmode=\"text\")\n",
    "                data = fetch_handle.read()\n",
    "                fetch_handle.close()\n",
    "                out_f.write(data)\n",
    "                time.sleep(0.5)\n",
    "\n",
    "        print(f\"Saved all seqs: {filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing tax id {tax_id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed70e27-b6fa-4fb3-8368-7cee9b19a6f0",
   "metadata": {},
   "source": [
    "# Fetch Genome seqs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00a1a12-6d7d-4d0f-a82e-e0072585406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez, SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7708fa14-253a-4fd9-91db-3c20c8b765e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Entrez.email = \"javadamn@gmai.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93920201-b579-41be-b662-54e972b68bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(\"/home/javad/pyprojects/MO_GEMs_Score/graphNN/data/strain_with_NCBIids.csv\")\n",
    "# xml_df= pd.read_csv('/home/aac/Mohammad/GNN/MetaBiomeX-main/data/strain_with_NCBIids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf7f75-19cf-4485-a169-5edfe82dd71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2966c4-f77b-491d-9408-723b43d199bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genome_accession(tax_id):\n",
    "    handle = Entrez.esearch(db=\"assembly\", term=f\"txid{tax_id}[Organism:exp] AND latest[filter]\", retmax=1)\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    if record['IdList']:\n",
    "        assembly_id = record['IdList'][0]\n",
    "        # Get assembly summary to find RefSeq accession\n",
    "        summary_handle = Entrez.esummary(db=\"assembly\", id=assembly_id)\n",
    "        summary_record = Entrez.read(summary_handle)\n",
    "        summary_handle.close()\n",
    "        asm_summary = summary_record['DocumentSummarySet']['DocumentSummary'][0]\n",
    "        refseq_acc = asm_summary.get(\"AssemblyAccession\")\n",
    "        return refseq_acc\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d13d36-6b35-4cf1-b199-7b4c69be2bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_Acc = data['ncbiid'].apply(get_genome_accession)\n",
    "data['genome_accession'] = gen_Acc\n",
    "# ncbi_ids = ['NC_' + str(x) for x in xml_df['ncbiid']]\n",
    "\n",
    "# ncbi_ids =ncbi_ids[1:3]\n",
    "# ncbi_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd03355c-1b11-46c6-a784-76d32016ad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd921a5-4880-415c-9ddc-c7f4c6084bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in data.iterrows():\n",
    "    tax_id = row[\"ncbiid\"]\n",
    "    accession = row[\"genome_accession\"]\n",
    "\n",
    "    if not accession:\n",
    "        print(f\"Skipping TaxID {tax_id} due to missing accession\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        handle = Entrez.esearch(db=\"nuccore\", term=f\"{accession}[Assembly Accession] AND refseq[filter]\", retmax=1)\n",
    "        record = Entrez.read(handle)\n",
    "        handle.close()\n",
    "\n",
    "        if record['IdList']:\n",
    "            seq_id = record['IdList'][0]\n",
    "            seq_handle = Entrez.efetch(db=\"nuccore\", id=seq_id, rettype=\"fasta\", retmode=\"text\")\n",
    "            records = list(SeqIO.parse(seq_handle, \"fasta\"))\n",
    "            seq_handle.close()\n",
    "\n",
    "            if records:\n",
    "                seq_record = records[0]\n",
    "                filename = f\"{tax_id}.fasta\"\n",
    "                with open(filename, \"w\") as output:\n",
    "                    SeqIO.write(seq_record, output, \"fasta\")\n",
    "                print(f\"Saved: {filename}\")\n",
    "            else:\n",
    "                print(f\"No FASTA records found for {accession} (TaxID {tax_id})\")\n",
    "        else:\n",
    "            print(f\"No sequence ID found for {accession} (TaxID {tax_id})\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {accession} (TaxID {tax_id}): {e}\")\n",
    "\n",
    "    time.sleep(0.4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf7903c-05e8-4d79-816a-fa5c3a157424",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ncbi_id in ncbi_ids:\n",
    "    handle = Entrez.efetch(db=\"nuccore\", id=ncbi_id, rettype=\"fasta\", retmode=\"text\")\n",
    "    seq_record = SeqIO.read(handle, \"fasta\")\n",
    "    handle.close()\n",
    "\n",
    "    # Save sequences to individual fasta files (optional)\n",
    "    with open(f\"{ncbi_id}.fasta\", \"w\") as output_handle:\n",
    "        SeqIO.write(seq_record, output_handle, \"fasta\")\n",
    "\n",
    "    print(f\"Sequence retrieved for {ncbi_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12979b1-1701-462d-8cb1-9abbb267fdfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benpyenv",
   "language": "python",
   "name": "benpyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
